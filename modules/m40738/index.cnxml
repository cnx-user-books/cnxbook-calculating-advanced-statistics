<document xmlns="http://cnx.rice.edu/cnxml">
  <title>18. Multiple Regression: Assumptions</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m40738</md:content-id>
  <md:title>18. Multiple Regression: Assumptions</md:title>
  <md:abstract/>
  <md:uuid>e348a267-a897-4d63-994e-5f7f7df58b16</md:uuid>
</metadata>

<content>
    <para id="eip-245"><media id="id27091673" alt=""><image src="../../media/ncpealogo.gif" mime-type="image/gif"/></media>

</para><note id="eip-278">This chapter is published by <link url="http://www.ncpeapublications.org/books.html">NCPEA Press</link> and is presented as an NCPEA/Connexions publication "print on demand book." Each chapter has been peer-reviewed, accepted, and endorsed by the National Council of Professors of Educational Administration (NCPEA) as a significant contribution to the scholarship and practice of education administration.

</note><list id="eip-29" list-type="labeled-item"><title><emphasis effect="underline">About the Authors</emphasis></title><item><emphasis>John R. Slate</emphasis> is a Professor at Sam Houston State University where he teaches Basic and Advanced Statistics courses, as well as professional writing, to doctoral students in Educational Leadership and Counseling.  His research interests lie in the use of educational databases, both state and national, to reform school practices.  To date, he has chaired and/or served over 100 doctoral student dissertation committees.  Recently, Dr. Slate created a website (<link url="www.writingandstatisticalhelp">Writing and Statistical Help</link>) to assist students and faculty with both statistical assistance and in editing/writing their dissertations/theses and manuscripts.</item>
	<item><emphasis>Ana Rojas-LeBouef </emphasis> is a Literacy Specialist at the Reading Center at Sam Houston State University where she teaches developmental reading courses.  Dr. LeBoeuf recently completed her doctoral degree in Reading, where she conducted a 16-year analysis of Texas statewide data regarding the achievement gap.  Her research interests lie in examining the inequities in achievement among ethnic groups.  Dr. Rojas-LeBouef also assists students and faculty in their writing and statistical needs on the Writing and Statistical Help website.
</item>
</list><para id="id1166735443955"><emphasis>In this set of steps, readers will learn how to conduct a multiple regression procedure. For detailed information regarding the assumptions underlying use of a multiple regression analysis, readers are referred to the Hyperstats Online Statistics Textbook at <link url="http://davidmlane.com/hyperstat/"><emphasis effect="bold">http://davidmlane.com/hyperstat/</emphasis></link> ; to the <emphasis effect="italics">Electronic Statistics Textbook</emphasis> (2011) at <link url="http://www.statsoft.com/textbook/"><emphasis effect="bold">http://www.statsoft.com/textbook/</emphasis></link> ; or to Andy Field’s (2009) Discovering Statistics Using SPSS at <link url="http://www.amazon.com/Discovering-Statistics-Introducing-Statistical-Method/dp/1847879071/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1304967862&amp;sr=1-1"><emphasis effect="bold">http://www.amazon.com/Discovering-Statistics-Introducing-Statistical-Method/dp/1847879071/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1304967862&amp;sr=1-1</emphasis></link> </emphasis></para>
    
    <para id="eip-916"><emphasis>Research questions for which a multiple regression analysis is appropriate involve determining variables that predict a continuous variable. For example, if you want to predict the life expectancy of individuals and you have archival data available (e.g., health history, gender), then a multiple regression analysis procedure could be utilized. Such a procedure could identify specific variables that are predictive of a long or of a short life expectancy. As such, interventions could be developed and targeted toward the variables that were statistically significant predictors. Other sample research questions for which a multiple regression analysis might be appropriate: (a) What factors predict high scores on a scholastic aptitude measure?; and (b) What factors are predictive of high scores on a life satisfaction scale? </emphasis></para><para id="eip-822"><emphasis>For the purposes of this chapter, our research question is: "What scholastic variables predict students' Full Scale IQ?"</emphasis></para><para id="eip-657"><emphasis>Have your data set open in SPSS. In this dataset, we will determine what variables, if any, are predictive of students’ Wechsler Full Scale IQ 3 (wifsiq). The 10 variables that we will use are: Picture Completion (pc), Information (inf), Coding (cod), Similarities (sim), Picture Arrangement (pa), Arithmetic (ari), Block Design (bd), Vocabulary (voc), Object Assembly (oa), and Comprehension (comp). </emphasis></para><para id="eip-332"><link url="17.1.png/image" window="new">
		<media id="media1" alt="">
			<image mime-type="image/png" src="../../media/17.1.png" id="figure1"/>
		</media>
	</link></para><para id="eip-422"><emphasis>As with every statistical procedure, we need to check the underlying assumptions. One assumption involves the data being normally distributed. To check this assumption, we recommend that you calculate the standardized skewness coefficients and the standardized kurtosis coefficients, as discussed in other chapters.</emphasis></para>
    <para id="eip-928"><emphasis>* Skewness [Note. Skewness refers to the extent to which the data are normally distributed around the mean. Skewed data involve having either mostly high scores with a few low ones or having mostly low scores with a few high ones.] Readers are referred to the following sources for a more detailed definition of skewness: <link url="http://www.statistics.com/index.php?page=glossary&amp;term_id=356">http://www.statistics.com/index.php?page=glossary&amp;term_id=356</link> and <link url="http://www.statsoft.com/textbook/basic-statistics/#Descriptive%20statisticsb">http://www.statsoft.com/textbook/basic-statistics/#Descriptive%20statisticsb</link> </emphasis></para><para id="eip-342"><emphasis>To standardize the skewness value so that its value can be constant across datasets and across studies, the following calculation must be made: Take the skewness value from the SPSS output and divide it by the Std. error of skewness. If the resulting calculation is within -3 to +3, then the skewness of the dataset is within the range of normality (Onwuegbuzie &amp; Daniel, 2002). If the resulting calculation is outside of this +/-3 range, the dataset is not normally distributed.</emphasis></para><para id="eip-654"><emphasis>* Kurtosis [Note. Kurtosis also refers to the extent to which the data are normally distributed around the mean. This time, the data are piled up higher than normal around the mean or piled up higher than normal at the ends of the distribution.] Readers are referred to the following sources for a more detailed definition of kurtosis: <link url="http://www.statistics.com/index.php?page=glossary&amp;term_id=326">http://www.statistics.com/index.php?page=glossary&amp;term_id=326</link> and <link url="http://www.statsoft.com/textbook/basic-statistics/#Descriptive%20statisticsb">http://www.statsoft.com/textbook/basic-statistics/#Descriptive%20statisticsb</link></emphasis></para><para id="eip-580"><emphasis>To standardize the kurtosis value so that its value can be constant across datasets and across studies, the following calculation must be made: Take the kurtosis value from the SPSS output and divide it by the Std. error of kurtosis. If the resulting calculation is within -3 to +3, then the kurtosis of the dataset is within the range of normality (Onwuegbuzie &amp; Daniel, 2002). If the resulting calculation is outside of this +/-3 range, the dataset is not normally distributed.</emphasis></para><para id="eip-549"><emphasis>Now that you have verified that your data are normally distributed, the extent to which linearity is present between each of the 10 independent variables listed above and the dependent variable of Full Scale IQ must be determined. For linearity, we will have SPSS conduct scatterplots for each IV and DV pair. </emphasis></para><para id="eip-674"><emphasis>√ Graphs</emphasis></para><para id="eip-95"><emphasis>√ Legacy Dialogs</emphasis></para><para id="eip-743"><emphasis>√ Scatter/Dot</emphasis></para><para id="eip-233"><link url="17.2.png/image" window="new">
		<media id="media2" alt="">
			<image mime-type="image/png" src="../../media/17.2.png" id="figure2"/>
		</media>
	</link></para><para id="eip-754"><emphasis>After clicking on Scatter/Dot, the following screen will appear. The Simple Scatter icon should be highlighted. If not, click on it.</emphasis></para><para id="eip-416"><emphasis>√ Click on Define</emphasis></para><para id="eip-431"><link url="17.3.png/image" window="new">
		<media id="media3" alt="">
			<image mime-type="image/png" src="../../media/17.3.png" id="figure3"/>
		</media>
	</link></para><para id="eip-209"><emphasis>The following screen should now be present. </emphasis></para><para id="eip-647"><link url="17.4.png/image" window="new">
		<media id="media4" alt="">
			<image mime-type="image/png" src="../../media/17.4.png" id="figure4"/>
		</media>
	</link></para><para id="eip-811"><emphasis>√ Drag one of the two variables of interest to the first box (Y axis) on the right hand side and the other variable of interest to the second box (X axis) on the right hand side. It does not matter which variable goes in the X or Y axis because your scatterplot results will be the same. For our purposes, we will place the variable we are trying to predict, Wechsler Full Scale IQ 3, in the Y Axis box and one of the variables (i.e., Performance 1) we will use to try to predict it.</emphasis></para><para id="eip-449"><emphasis>√ Once you have a variable in each of the first two boxes, click on the OK tab on the bottom left hand corner of the screen. </emphasis></para><para id="eip-497"><link url="17.5.png/image" window="new">
		<media id="media5" alt="">
			<image mime-type="image/png" src="../../media/17.5.png" id="figure5"/>
		</media>
	</link></para><para id="eip-766"><emphasis>√ Look at the scatterplot to determine whether a linear relationship is present. In the screenshot below, the relationship is very clearly linear.</emphasis></para><para id="eip-20"><link url="17.6.png/image" window="new">
		<media id="media6" alt="">
			<image mime-type="image/png" src="../../media/17.6.png" id="figure6"/>
		</media>
	</link></para><para id="eip-133"><emphasis>You will need to repeat this process, for this example, nine more times. Leave the dependent variable of Wechsler Full Scale IQ 3 in the Y Axis box and replace the variable in the X Axis box with the next variable (i.e., Verbal 1). Then click on OK.</emphasis></para><para id="eip-393"><link url="17.7.png/image" window="new">
		<media id="media7" alt="">
			<image mime-type="image/png" src="../../media/17.7.png" id="figure7"/>
		</media>
	</link></para><para id="eip-594"><emphasis>After you have verified that linearity is present for each independent variable with the dependent variable, we will examine the extent to which multicollinearity is not present. Multicollinearity refers to having variables that are highly correlated with each other. When variables are highly correlated in a multiple regression analysis, the unique contribution of each variable in predicting the dependent variable is difficult to determine. The reason for this difficulty is that highly interrelated variables are being used to predict the same variance in the dependent variable. Researchers/statisticians disagree on the specific correlation value that must be present for multicollinearity to exist. Some persons contend that correlations above .70 are necessary whereas other persons contend that the correlations must be above .90 for multicollinearity to exist.</emphasis></para><para id="eip-455"><emphasis>If multicollinearity is present, you can leave it as it is, and have SPSS calculate the multiple regression. Multicollinearity influences the results regarding each predictor’s unique contribution. If your interest is in the overall or combined effect of the statistically significant predictors, then multicollinearity is not an issue. Other choices would be to remove one or more of the highly correlated variables from the regression analysis or to create an aggregate or composite of the highly correlated variables.</emphasis>

</para><para id="eip-372"><emphasis>The choice that we recommend is to have SPSS calculate multicollinearity when the multiple regression analysis is calculated. More on this later.</emphasis></para>
  </content>
</document>